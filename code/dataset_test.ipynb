{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import interpolate\n",
    "import json\n",
    "import csv\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNpStats(matrix):\n",
    "    print(\"Shape:\", matrix.shape)\n",
    "    print(\"Mean:\", np.mean(matrix))\n",
    "    print(\"Variance:\", np.var(matrix))\n",
    "    print(\"Max:\", np.max(matrix))\n",
    "    print(\"Min:\", np.min(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "def pad_to_patch_size(x, patch_size):\n",
    "    assert x.ndim == 2\n",
    "    return np.pad(x, ((0,0),(0, patch_size-x.shape[1]%patch_size)), 'wrap')\n",
    "def normalize(x, mean=None, std=None):\n",
    "    mean = np.mean(x) if mean is None else mean\n",
    "    std = np.std(x) if std is None else std\n",
    "    return (x - mean) / (std * 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/isilon/CSC6/HelenZhouLab/HZLHD0/InternsnStudents/Interns/jonathan/datasets/NSD'\n",
    "subjects = ['subj01', 'subj02', 'subj03', 'subj04', 'subj05', 'subj06', 'subj07', 'subj08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH training fMRI data shape:\n",
      "(9841, 19004)\n",
      "(Training stimulus images × LH vertices)\n",
      "\n",
      "RH training fMRI data shape:\n",
      "(9841, 20544)\n",
      "(Training stimulus images × RH vertices)\n"
     ]
    }
   ],
   "source": [
    "sub = \"subj01\"\n",
    "\n",
    "fmri_dir = os.path.join(path, sub, 'training_split', 'training_fmri')\n",
    "lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
    "rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
    "\n",
    "print('LH training fMRI data shape:')\n",
    "print(lh_fmri.shape)\n",
    "print('(Training stimulus images × LH vertices)')\n",
    "\n",
    "print('\\nRH training fMRI data shape:')\n",
    "print(rh_fmri.shape)\n",
    "print('(Training stimulus images × RH vertices)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9841, 39548)\n"
     ]
    }
   ],
   "source": [
    "fmri_sub = np.concatenate((lh_fmri, rh_fmri), axis=1)\n",
    "print(fmri_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (9841, 39548)\n",
      "Mean: 0.0021823181\n",
      "Variance: 0.50268227\n",
      "Max: 6.3958163\n",
      "Min: -6.224722\n"
     ]
    }
   ],
   "source": [
    "printNpStats(fmri_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (9841, 39552)\n",
      "Mean: -5.3962856e-09\n",
      "Variance: 1.0000061\n",
      "Max: 9.017823\n",
      "Min: -8.7826605\n"
     ]
    }
   ],
   "source": [
    "fmri_sub = normalize(pad_to_patch_size(fmri_sub, patch_size))\n",
    "printNpStats(fmri_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_dir = os.path.join(path, sub, 'roi_masks')\n",
    "\n",
    "hemisphere = 'left' #@param ['left', 'right'] {allow-input: true}\n",
    "roi = \"V1v\" #@param [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\", \"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\", \"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\", \"OPA\", \"PPA\", \"RSC\", \"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\", \"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"] {allow-input: true}\n",
    "\n",
    "# Define the ROI class based on the selected ROI\n",
    "if roi in [\"V1v\", \"V1d\", \"V2v\", \"V2d\", \"V3v\", \"V3d\", \"hV4\"]:\n",
    "    roi_class = 'prf-visualrois'\n",
    "elif roi in [\"EBA\", \"FBA-1\", \"FBA-2\", \"mTL-bodies\"]:\n",
    "    roi_class = 'floc-bodies'\n",
    "elif roi in [\"OFA\", \"FFA-1\", \"FFA-2\", \"mTL-faces\", \"aTL-faces\"]:\n",
    "    roi_class = 'floc-faces'\n",
    "elif roi in [\"OPA\", \"PPA\", \"RSC\"]:\n",
    "    roi_class = 'floc-places'\n",
    "elif roi in [\"OWFA\", \"VWFA-1\", \"VWFA-2\", \"mfs-words\", \"mTL-words\"]:\n",
    "    roi_class = 'floc-words'\n",
    "elif roi in [\"early\", \"midventral\", \"midlateral\", \"midparietal\", \"ventral\", \"lateral\", \"parietal\"]:\n",
    "    roi_class = 'streams'\n",
    "    \n",
    "# Load the ROI brain surface maps\n",
    "challenge_roi_class_dir = os.path.join(roi_dir, hemisphere[0]+'h.'+roi_class+'_challenge_space.npy')\n",
    "fsaverage_roi_class_dir = os.path.join(roi_dir, hemisphere[0]+'h.'+roi_class+'_fsaverage_space.npy')\n",
    "roi_map_dir = os.path.join(roi_dir, 'mapping_'+roi_class+'.npy')\n",
    "\n",
    "challenge_roi_class = np.load(challenge_roi_class_dir)\n",
    "fsaverage_roi_class = np.load(fsaverage_roi_class_dir)\n",
    "roi_map = np.load(roi_map_dir, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(challenge_roi_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(path, sub, 'training_split', 'training_images')\n",
    "img_list = os.listdir(img_dir)\n",
    "img_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test datasets\n",
    "# Calculate how many stimulus images correspond to 90% of the training data\n",
    "num_train = int(np.round(len(img_list) / 100 * 90))\n",
    "# Shuffle all training stimulus images\n",
    "idxs = np.arange(len(img_list))\n",
    "np.random.shuffle(idxs)\n",
    "# Assign 90% of the shuffled stimulus images to the training partition,\n",
    "# and 10% to the test partition\n",
    "idxs_train, idxs_test = idxs[:num_train], idxs[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img_list = [os.path.join(img_dir, filename) for filename in img_list]\n",
    "img_train_sub = np.array(full_img_list)[idxs_train]\n",
    "img_test_sub = np.array(full_img_list)[idxs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8857,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate([img_train_sub, img_test_sub], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path).convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)), # resize the images to 224x24 pixels\n",
    "    transforms.ToTensor(), # convert the images to a PyTorch tensor\n",
    "    identity\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "(3, 256, 256)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tensor_img = transform(img)\n",
    "numpy_img = tensor_img.numpy()\n",
    "numpy_img = np.transpose(numpy_img, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (256, 256, 3)\n",
      "Mean: 0.5122223\n",
      "Variance: 0.08787003\n",
      "Max: 1.0\n",
      "Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "printNpStats(numpy_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOLD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/isilon/CSC6/HelenZhouLab/HZLHD0/InternsnStudents/Interns/jonathan/datasets/BOLD5000'\n",
    "patch_size = 16\n",
    "image_transform = identity\n",
    "subjects = ['CSI1', 'CSI2', 'CSI3', 'CSI4']\n",
    "include_nonavg_test = False\n",
    "roi_list = ['EarlyVis', 'LOC', 'OPA', 'PPA', 'RSC']\n",
    "\n",
    "fmri_path = os.path.join(path, 'BOLD5000_GLMsingle_ROI_betas/py')\n",
    "img_path = os.path.join(path, 'BOLD5000_Stimuli')\n",
    "imgs_dict = np.load(os.path.join(img_path, 'Scene_Stimuli/Presented_Stimuli/img_dict.npy'),allow_pickle=True).item()\n",
    "repeated_imgs_list = np.loadtxt(os.path.join(img_path, 'Scene_Stimuli', 'repeated_stimuli_113_list.txt'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_files = [f for f in os.listdir(fmri_path) if f.endswith('.npy')]\n",
    "fmri_files.sort()\n",
    "\n",
    "sub = \"CSI1\"\n",
    "\n",
    "# load fmri\n",
    "fmri_data_sub = []\n",
    "for roi in roi_list:\n",
    "    for npy in fmri_files:\n",
    "        if npy.endswith('.npy') and sub in npy and roi in npy:\n",
    "            fmri_data_sub.append(np.load(os.path.join(fmri_path, npy)))\n",
    "fmri_data_sub = np.concatenate(fmri_data_sub, axis=-1) # concatenate all rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5254, 1685)\n",
      "Mean: -6.253479e-10\n",
      "Variance: 1.0000005\n",
      "Max: 8.60656\n",
      "Min: -10.2187605\n"
     ]
    }
   ],
   "source": [
    "printNpStats(fmri_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5254, 1696)\n",
      "Mean: -4.9905635e-10\n",
      "Variance: 1.0\n",
      "Max: 8.606558\n",
      "Min: -10.218758\n"
     ]
    }
   ],
   "source": [
    "fmri_data_sub = normalize(pad_to_patch_size(fmri_data_sub, patch_size))\n",
    "printNpStats(fmri_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimuli_list(root, sub):\n",
    "    sti_name = []\n",
    "    path = os.path.join(root, 'Stimuli_Presentation_Lists', sub)\n",
    "    folders = os.listdir(path)\n",
    "    folders.sort()\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(os.path.join(path, folder)):\n",
    "            continue\n",
    "        files = os.listdir(os.path.join(path, folder))\n",
    "        files.sort()\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                sti_name += list(np.loadtxt(os.path.join(path, folder, file), dtype=str))\n",
    "\n",
    "    sti_name_to_return = []\n",
    "    for name in sti_name:\n",
    "        if name.startswith('rep_'):\n",
    "            name = name.replace('rep_', '', 1)\n",
    "        sti_name_to_return.append(name)\n",
    "    return sti_name_to_return\n",
    "\n",
    "# load image\n",
    "img_files = get_stimuli_list(img_path, sub)\n",
    "img_data_sub = [imgs_dict[name] for name in img_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_get_all_index(list, value):\n",
    "    return [i for i, v in enumerate(list) if v == value]\n",
    "\n",
    "# split train test\n",
    "test_idx = [list_get_all_index(img_files, img) for img in repeated_imgs_list]\n",
    "test_idx = [i for i in test_idx if len(i) > 0] # remove empy list for CSI4\n",
    "test_fmri = np.stack([fmri_data_sub[idx].mean(axis=0) for idx in test_idx])\n",
    "test_img = np.stack([img_data_sub[idx[0]] for idx in test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx_flatten = []\n",
    "for idx in test_idx:\n",
    "    test_idx_flatten += idx # flatten\n",
    "if include_nonavg_test:\n",
    "    test_fmri = np.concatenate([test_fmri, fmri_data_sub[test_idx_flatten]], axis=0)\n",
    "    test_img = np.concatenate([test_img, np.stack([img_data_sub[idx] for idx in test_idx_flatten])], axis=0)\n",
    "\n",
    "train_idx = [i for i in range(len(img_files)) if i not in test_idx_flatten]\n",
    "train_img = np.stack([img_data_sub[idx] for idx in train_idx])\n",
    "train_fmri = fmri_data_sub[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4803, 256, 256, 3)\n",
      "Mean: 107.18298585843937\n",
      "Variance: 3806.3570156922074\n",
      "Max: 255\n",
      "Min: 0\n"
     ]
    }
   ],
   "source": [
    "printNpStats(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4803, 1696)\n",
      "Mean: -0.0009539404\n",
      "Variance: 1.0008868\n",
      "Max: 8.606558\n",
      "Min: -10.218758\n"
     ]
    }
   ],
   "source": [
    "printNpStats(train_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (113, 256, 256, 3)\n",
      "Mean: 107.49450116452918\n",
      "Variance: 4136.151750152919\n",
      "Max: 255\n",
      "Min: 0\n"
     ]
    }
   ],
   "source": [
    "printNpStats(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (113, 1696)\n",
      "Mean: 0.010219635\n",
      "Variance: 0.32646358\n",
      "Max: 2.624513\n",
      "Min: -2.789681\n"
     ]
    }
   ],
   "source": [
    "printNpStats(test_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (256, 256, 3)\n",
      "Mean: 0.4586419398488561\n",
      "Variance: 0.01421589155821275\n",
      "Max: 0.9764705882352941\n",
      "Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "pog_img = test_img[5] / 255.0\n",
    "printNpStats(pog_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
